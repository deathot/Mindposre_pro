{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7761be-840e-4fc8-b501-7a5f9a0a56b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from skvideo.io import vreader, FFmpegWriter\n",
    "from ais_bench.infer.interface import InferSession\n",
    "\n",
    "from det_utils import letterbox, scale_coords, nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9292fc-f49c-410d-8bf3-08069171c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, cfg, bgr2rgb=True):\n",
    "    img, scale_ratio, pad_size = letterbox(image, new_shape=cfg['input_shape'])\n",
    "    if bgr2rgb:\n",
    "        img = img[:, :, ::-1]\n",
    "    img = img.transpose(2, 0, 1)  # HWC2CHW\n",
    "    img = np.ascontiguousarray(img, dtype=np.float16) / 255.0\n",
    "    return img, scale_ratio, pad_size\n",
    "\n",
    "\n",
    "def draw_bbox(bbox, img0, color, wt, names):\n",
    "    det_result_str = ''\n",
    "    for idx, class_id in enumerate(bbox[:, 5]):\n",
    "        if float(bbox[idx][4] < float(0.05)):\n",
    "            continue\n",
    "        img0 = cv2.rectangle(img0, (int(bbox[idx][0]), int(bbox[idx][1])), (int(bbox[idx][2]), int(bbox[idx][3])),\n",
    "                             color, wt)\n",
    "        img0 = cv2.putText(img0, str(idx) + ' ' + names[int(class_id)], (int(bbox[idx][0]), int(bbox[idx][1] + 16)),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        img0 = cv2.putText(img0, '{:.4f}'.format(bbox[idx][4]), (int(bbox[idx][0]), int(bbox[idx][1] + 32)),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        det_result_str += '{} {} {} {} {} {}\\n'.format(\n",
    "            names[bbox[idx][5]], str(bbox[idx][4]), bbox[idx][0], bbox[idx][1], bbox[idx][2], bbox[idx][3])\n",
    "    return img0\n",
    "\n",
    "\n",
    "def get_labels_from_txt(path):\n",
    "    labels_dict = dict()\n",
    "    with open(path) as f:\n",
    "        for cat_id, label in enumerate(f.readlines()):\n",
    "            labels_dict[cat_id] = label.strip()\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def draw_prediction(pred, image, labels):\n",
    "    imgbox = widgets.Image(format='jpg', height=720, width=1280)\n",
    "    img_dw = draw_bbox(pred, image, (0, 255, 0), 2, labels)\n",
    "    imgbox.value = cv2.imencode('.jpg', img_dw)[1].tobytes()\n",
    "    display(imgbox)\n",
    "\n",
    "\n",
    "def infer_image(img_path, model, class_names, cfg):\n",
    "    image = cv2.imread(img_path)\n",
    "    img, scale_ratio, pad_size = preprocess_image(image, cfg)\n",
    "    output = model.infer([img])[0]\n",
    "\n",
    "    output = torch.tensor(output)\n",
    "    boxout = nms(output, conf_thres=cfg[\"conf_thres\"], iou_thres=cfg[\"iou_thres\"])\n",
    "    pred_all = boxout[0].numpy()\n",
    "    scale_coords(cfg['input_shape'], pred_all[:, :4], image.shape, ratio_pad=(scale_ratio, pad_size))\n",
    "    draw_prediction(pred_all, image, class_names)\n",
    "\n",
    "\n",
    "def infer_frame_with_vis(image, model, labels_dict, cfg, bgr2rgb=True):\n",
    "    img, scale_ratio, pad_size = preprocess_image(image, cfg, bgr2rgb)\n",
    "    output = model.infer([img])[0]\n",
    "\n",
    "    output = torch.tensor(output)\n",
    "    boxout = nms(output, conf_thres=cfg[\"conf_thres\"], iou_thres=cfg[\"iou_thres\"])\n",
    "    pred_all = boxout[0].numpy()\n",
    "    scale_coords(cfg['input_shape'], pred_all[:, :4], image.shape, ratio_pad=(scale_ratio, pad_size))\n",
    "    img_vis = draw_bbox(pred_all, image, (0, 255, 0), 2, labels_dict)\n",
    "    return img_vis\n",
    "\n",
    "\n",
    "def img2bytes(image):\n",
    "    return bytes(cv2.imencode('.jpg', image)[1])\n",
    "\n",
    "\n",
    "def infer_video(video_path, model, labels_dict, cfg, output_path='output.mp4'):\n",
    "    image_widget = widgets.Image(format='jpeg', width=1280, height=720)\n",
    "    display(image_widget)\n",
    "\n",
    "    cap = vreader(video_path)\n",
    "    video_writer = None\n",
    "    for img_frame in cap:\n",
    "        image_pred = infer_frame_with_vis(img_frame, model, labels_dict, cfg, bgr2rgb=False)\n",
    "        image_widget.value = img2bytes(image_pred[:, :, ::-1])\n",
    "\n",
    "        if video_writer is None:\n",
    "            video_writer = FFmpegWriter(output_path)\n",
    "        video_writer.writeFrame(image_pred)\n",
    "    video_writer.close()\n",
    "\n",
    "\n",
    "def infer_camera(model, labels_dict, cfg):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    image_widget = widgets.Image(format='jpeg', width=1280, height=720)\n",
    "    display(image_widget)\n",
    "    while True:\n",
    "        _, img_frame = cap.read()\n",
    "        image_pred = infer_frame_with_vis(img_frame, model, labels_dict, cfg)\n",
    "        image_widget.value = img2bytes(image_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccded13-fad1-4b88-b63f-d46deb23aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'conf_thres': 0.4,\n",
    "    'iou_thres': 0.5,\n",
    "    'input_shape': [640, 640],\n",
    "}\n",
    "\n",
    "model_path = 'yolov5s_bs1.om'\n",
    "label_path = './coco_names.txt'\n",
    "model = InferSession(0, model_path)\n",
    "labels_dict = get_labels_from_txt(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93110e-fcfb-4382-bdee-f5b084b7549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_mode = 'image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab68b6b-7d65-4dd9-ab0b-c5c9733c415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if infer_mode == 'image':\n",
    "    img_path = 'world_cup.jpg'\n",
    "    infer_image(img_path, model, labels_dict, cfg)\n",
    "elif infer_mode == 'camera':\n",
    "    infer_camera(model, labels_dict, cfg)\n",
    "elif infer_mode == 'video':\n",
    "    video_path = 'world_cup.mp4'\n",
    "    infer_video(video_path, model, labels_dict, cfg, output_path='output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64b8f8-fa03-403d-afe6-396a0d4bd777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
