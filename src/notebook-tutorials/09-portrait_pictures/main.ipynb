{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9485df33",
   "metadata": {},
   "source": [
    "# 样例介绍\n",
    "* 目前工业界通用的人像分割主要采用绿屏技术，需要专门的绿屏设备及环境，不利于普通用户的广泛使用。在这个样例中，我们使用了一个深度学习神经网络PortraitNet，能够实时地进行人像分割和背景替换。\n",
    "\n",
    "# 前期准备\n",
    "* 基础镜像的样例目录中已包含转换后的om模型以及测试图片，如果直接运行，可跳过此步骤。如果需要重新转换模型，可参考如下步骤：\n",
    "* 首先我们可以在[这个链接](https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Atlas%20200I%20DK%20A2/DevKit/downloads/23.0.RC1/Ascend-devkit_23.0.RC1_downloads.xlsx)的表格中找到本样例的依赖文件，下载我们已经准备好了的TensorFlow模型文件，TensorFlow是开源的深度学习框架。\n",
    "\n",
    "* 为了能进一步优化模型推理性能，我们需要将其转换为om模型进行使用，以下为转换指令： \n",
    "    ```shell\n",
    "    atc --model=./portrait.pb  --insert_op_conf=./insert_op.cfg  --output=\"./portrait\" --output_type=FP32 --input_shape=\"Inputs/x_input:1,224,224,3\" --framework=3 --soc_version=Ascend310B1\n",
    "    ```\n",
    "    其中转换参数的含义为：\n",
    "    * --model：输入模型路径\n",
    "    * --insert_op_conf：插入算子的配置文件路径与文件名\n",
    "    * --output：输出模型路径\n",
    "    * --output_type：指定网络输出数据类型或指定某个输出节点的输出类型\n",
    "    * --input_shape：指定模型输入数据的shape\n",
    "    * --framework：原始网络模型框架类型，3表示TensorFlow\n",
    "    * --soc_version：昇腾AI处理器型号\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d338de",
   "metadata": {},
   "source": [
    "# 模型推理实现\n",
    "* 导入代码依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import acl\n",
    "import acllite_utils as utils\n",
    "import constants as const\n",
    "from acllite_imageproc import AclLiteImageProc\n",
    "from acllite_model import AclLiteModel\n",
    "from acllite_image import AclLiteImage\n",
    "from acllite_resource import resource_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a553a9",
   "metadata": {},
   "source": [
    "* 主要推理代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87998937-6094-4639-a47d-66f67d41043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AclLiteResource:\n",
    "    \"\"\"AclLite资源管理\"\"\"\n",
    "    def __init__(self, device_id=0):\n",
    "        self.device_id = device_id\n",
    "        self.context = None\n",
    "        self.stream = None\n",
    "        self.run_mode = None\n",
    "        \n",
    "    def init(self):\n",
    "        \"\"\"初始化ACL相关资源\"\"\"\n",
    "        print(\"init resource stage:\")\n",
    "        ret = acl.init()\n",
    "\n",
    "        ret = acl.rt.set_device(self.device_id)\n",
    "        utils.check_ret(\"acl.rt.set_device\", ret)\n",
    "\n",
    "        self.context, ret = acl.rt.create_context(self.device_id)\n",
    "        utils.check_ret(\"acl.rt.create_context\", ret)\n",
    "\n",
    "        self.stream, ret = acl.rt.create_stream()\n",
    "        utils.check_ret(\"acl.rt.create_stream\", ret)\n",
    "\n",
    "        self.run_mode, ret = acl.rt.get_run_mode()\n",
    "        utils.check_ret(\"acl.rt.get_run_mode\", ret)\n",
    "\n",
    "        print(\"Init resource success\")\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"释放ACL相关资源\"\"\"\n",
    "        print(\"acl resource release all resource\")\n",
    "        resource_list.destroy()\n",
    "        if self.stream:\n",
    "            print(\"acl resource release stream\")\n",
    "            acl.rt.destroy_stream(self.stream)\n",
    "\n",
    "        if self.context:\n",
    "            print(\"acl resource release context\")\n",
    "            acl.rt.destroy_context(self.context)\n",
    "\n",
    "        print(\"Reset acl device \", self.device_id)\n",
    "        acl.rt.reset_device(self.device_id)\n",
    "        print(\"Release acl resource success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7316be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seg(object):\n",
    "    \"\"\"人像分割模型推理\"\"\"\n",
    "    def __init__(self, model_path, model_width, model_height):\n",
    "        self._model_path = model_path\n",
    "        self._model_width = model_width\n",
    "        self._model_height = model_height\n",
    "        self.device_id = 0\n",
    "        self._dvpp = None\n",
    "        self._model = None\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"初始化相关资源\"\"\"\n",
    "        # Initialize dvpp\n",
    "        self._dvpp = AclLiteImageProc()\n",
    "\n",
    "        # Load model\n",
    "        self._model = AclLiteModel(self._model_path)\n",
    "\n",
    "        return const.SUCCESS\n",
    "\n",
    "    @utils.display_time\n",
    "    def pre_process(self, image):\n",
    "        \"\"\"图片预处理\"\"\"\n",
    "        image_dvpp = image.copy_to_dvpp()\n",
    "        yuv_image = self._dvpp.jpegd(image_dvpp)\n",
    "        resized_image = self._dvpp.resize(yuv_image,\n",
    "                                          self._model_width, self._model_height)\n",
    "        return resized_image     \n",
    "\n",
    "    @utils.display_time\n",
    "    def inference(self, input_data):\n",
    "        \"\"\"模型推理\"\"\"\n",
    "        return self._model.execute(input_data)\n",
    "\n",
    "    @utils.display_time\n",
    "    def post_process(self, infer_output, image_name):\n",
    "        \"\"\"获取分割结果\"\"\"\n",
    "        data = infer_output[0]\n",
    "        vals = data.flatten()\n",
    "        mask = np.clip((vals * 255), 0, 255)\n",
    "        mask = mask.reshape(224, 224, 2)\n",
    "        cv2.imwrite(os.path.join(MASK_DIR, image_name), mask[:, :, 0])\n",
    "        return mask \n",
    "\n",
    "    \n",
    "@utils.display_time\n",
    "def background_replace(bg_path, ori_path, mask_path):\n",
    "    \"\"\"将人像分割结果与背景图片结合\"\"\"\n",
    "    background = cv2.imread(bg_path)\n",
    "    height, width = background.shape[:2]\n",
    "    ori_img = cv2.imread(ori_path)\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    mask = mask / 255\n",
    "    mask_resize = cv2.resize(mask, (width, height))\n",
    "    ori_img = cv2.resize(ori_img, (width, height))\n",
    "    mask_bg = np.repeat(mask_resize[..., np.newaxis], 3, 2)\n",
    "    result = np.uint8(background * mask_bg + ori_img * (1 - mask_bg))\n",
    "    cv2.imwrite(os.path.join(OUTPUT_DIR, os.path.basename(mask_path)), result)\n",
    "\n",
    "    \n",
    "def main():\n",
    "    \"\"\"推理主函数\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(MASK_DIR, exist_ok=True)\n",
    "\n",
    "    acl_resource = AclLiteResource()\n",
    "    acl_resource.init()\n",
    "\n",
    "    seg = Seg(MODEL_PATH, MODEL_WIDTH, MODEL_HEIGHT)\n",
    "    ret = seg.init()\n",
    "    utils.check_ret(\"seg.init \", ret)\n",
    "\n",
    "    images_list = [os.path.join(IMAGE_DIR, img)\n",
    "                   for img in os.listdir(IMAGE_DIR)\n",
    "                   if os.path.splitext(img)[1] in const.IMG_EXT]\n",
    "\n",
    "    for image_file in images_list:\n",
    "        image_name = os.path.basename(image_file)\n",
    "        if image_name != 'background.jpg':\n",
    "            print('====' + image_name + '====')\n",
    "            # read image\n",
    "            image = AclLiteImage(image_file)\n",
    "            # Preprocess the picture\n",
    "            resized_image = seg.pre_process(image)\n",
    "            # Inference\n",
    "            result = seg.inference([resized_image, ])\n",
    "            # Post-processing\n",
    "            mask = seg.post_process(result, image_name)\n",
    "            # Fusion of segmented portrait and background image\n",
    "            background_replace(os.path.join(IMAGE_DIR, 'background.jpg'), \\\n",
    "                                        image_file, os.path.join(MASK_DIR, image_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b122c777",
   "metadata": {},
   "source": [
    "# 样例运行\n",
    "\n",
    "* 运行以下代码后，我们就可以看到人像背景替换效果了。左边是原始的人像图片，右边是替换人像背景后的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128978d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "currentPath = '.'\n",
    "OUTPUT_DIR = os.path.join(currentPath, 'out/result')\n",
    "MASK_DIR = os.path.join(currentPath, 'out/mask')\n",
    "MODEL_PATH = os.path.join(currentPath,\"./model/portrait.om\")\n",
    "IMAGE_DIR = os.path.join(currentPath, \"data\" )\n",
    "MODEL_WIDTH = 224\n",
    "MODEL_HEIGHT = 224\n",
    "\n",
    "main()\n",
    "\n",
    "path = os.path.join(IMAGE_DIR, 'ori.jpg')\n",
    "original = cv2.imread(path)[:, :, ::-1]\n",
    "\n",
    "path = os.path.join(OUTPUT_DIR, 'ori.jpg')\n",
    "result = cv2.imread(path)[:, :, ::-1]\n",
    "\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=2)\n",
    "for ax, image in zip(axarr, [original, result]):\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6eab85-6049-4029-9905-90826897fd0d",
   "metadata": {},
   "source": [
    "# 样例总结与扩展\n",
    "以上就是这个样例的全部内容了，通过这个样例，我们可以发现借助深度学习神经网络，以往费时费力的人像背景替换工作可以变得如此简单高效。大家可以尝试使用其他图片，测试一下人像背景替换效果哦。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
