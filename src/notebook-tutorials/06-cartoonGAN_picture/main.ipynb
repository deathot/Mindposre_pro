{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6aa99c",
   "metadata": {},
   "source": [
    "# 样例介绍\n",
    "\n",
    "功能：使用cartoonGAN模型对输入图片进行卡通化处理。  \n",
    "样例输入：原始图片jpg文件。  \n",
    "样例输出：卡通图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1451fc2e",
   "metadata": {},
   "source": [
    "# 前期准备\n",
    "\n",
    "基础镜像的样例目录中已包含转换后的om模型以及测试图片，如果直接运行，可跳过此步骤。如果需要重新转换模型，可参考如下步骤：\n",
    "\n",
    "1. 获取模型和测试数据。我们可以在[这个链接](https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Atlas%20200I%20DK%20A2/DevKit/downloads/23.0.RC1/Ascend-devkit_23.0.RC1_downloads.xlsx)的表格中找到本样例的依赖文件，将模型和测试数据下载到本地，并放到本样例目录下。\n",
    "\n",
    "2. 模型转换。利用atc工具将原始模型转换为om模型，转换命令如下：  \n",
    "    ```shell\n",
    "    atc --output_type=FP32 --input_shape=\"train_real_A:1,256,256,3\" --input_format=NHWC --output=\"./cartoonization\" --soc_version=Ascend310B1 --insert_op_conf=insert_op.cfg --framework=3 --save_original_model=false --model=\"./cartoonization.pb\" --precision_mode=allow_fp32_to_fp16\n",
    "    ```\n",
    "\n",
    "    其中各个参数具体含义如下：\n",
    "    * --output_type：指定网络输出数据类型。\n",
    "    * --input_shape：模型的输入节点名称和形状。\n",
    "    * --input_format：输入Tensor的内存排列方式。\n",
    "    * --output：输出的模型文件路径。\n",
    "    * --soc_version：昇腾AI处理器型号，此处为\"Ascend310B1\"。\n",
    "    * --insert_op_conf：插入算子的配置文件路径与文件名，例如aipp预处理算子。\n",
    "    * --framework：原始框架类型,  0: Caffe, 1: MindSpore, 3: TensorFlow, 5: ONNX。\n",
    "    * --save_original_model：转换后是否保留原始模型文件。\n",
    "    * --model：原始模型文件路径。\n",
    "    * --precision_mode：选择算子精度模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82653e5f",
   "metadata": {},
   "source": [
    "# 模型推理实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a2799-c2f5-405f-a4b1-722248655aa8",
   "metadata": {},
   "source": [
    "### 1. 导入三方库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e0abe-f4f5-4a29-8af8-4e082955d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import acl\n",
    "\n",
    "import acllite_utils as utils\n",
    "import constants as const\n",
    "from acllite_imageproc import AclLiteImageProc\n",
    "from acllite_model import AclLiteModel\n",
    "from acllite_image import AclLiteImage\n",
    "from acllite_resource import resource_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30643cc9-9015-433b-8c31-66ed14cabdfe",
   "metadata": {},
   "source": [
    "### 2. 定义acllite资源初始化与去初始化类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096cb19-e3e6-49fd-a38e-f55750f41154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AclLiteResource:\n",
    "    \"\"\"\n",
    "    AclLiteResource\n",
    "    \"\"\"\n",
    "    def __init__(self, device_id=0):\n",
    "        self.device_id = device_id\n",
    "        self.context = None\n",
    "        self.stream = None\n",
    "        self.run_mode = None\n",
    "        \n",
    "    def init(self):\n",
    "        \"\"\"\n",
    "        init resource\n",
    "        \"\"\"\n",
    "        print(\"init resource stage:\")\n",
    "        ret = acl.init()\n",
    "\n",
    "        ret = acl.rt.set_device(self.device_id)\n",
    "        utils.check_ret(\"acl.rt.set_device\", ret)\n",
    "\n",
    "        self.context, ret = acl.rt.create_context(self.device_id)\n",
    "        utils.check_ret(\"acl.rt.create_context\", ret)\n",
    "\n",
    "        self.stream, ret = acl.rt.create_stream()\n",
    "        utils.check_ret(\"acl.rt.create_stream\", ret)\n",
    "\n",
    "        self.run_mode, ret = acl.rt.get_run_mode()\n",
    "        utils.check_ret(\"acl.rt.get_run_mode\", ret)\n",
    "\n",
    "        print(\"Init resource success\")\n",
    "\n",
    "    def __del__(self):\n",
    "        print(\"acl resource release all resource\")\n",
    "        resource_list.destroy()\n",
    "        if self.stream:\n",
    "            print(\"acl resource release stream\")\n",
    "            acl.rt.destroy_stream(self.stream)\n",
    "\n",
    "        if self.context:\n",
    "            print(\"acl resource release context\")\n",
    "            acl.rt.destroy_context(self.context)\n",
    "\n",
    "        print(\"Reset acl device \", self.device_id)\n",
    "        acl.rt.reset_device(self.device_id)\n",
    "        print(\"Release acl resource success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab3af4-e881-432e-a3f2-9461666f6dbc",
   "metadata": {},
   "source": [
    "### 3. 定义卡通化类，包含前处理、推理、后处理等操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1bed4-24e4-4ece-8c53-41cf24a74eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cartoonization(object):\n",
    "    \"\"\"\n",
    "    class for Cartoonization\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, model_width, model_height):\n",
    "        self._model_path = model_path\n",
    "        self._model_width = model_width\n",
    "        self._model_height = model_height\n",
    "        self.device_id = 0\n",
    "        self._dvpp = None\n",
    "        self._model = None\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"\n",
    "        Initialize\n",
    "        \"\"\"\n",
    "        # Initialize dvpp\n",
    "        self._dvpp = AclLiteImageProc()\n",
    "\n",
    "        # Load model\n",
    "        self._model = AclLiteModel(self._model_path)\n",
    "\n",
    "        return const.SUCCESS\n",
    " \n",
    "    @utils.display_time\n",
    "    def pre_process(self, image):\n",
    "        \"\"\"\n",
    "        image preprocess\n",
    "        \"\"\"\n",
    "        image_dvpp = image.copy_to_dvpp()\n",
    "        yuv_image = self._dvpp.jpegd(image_dvpp)  # 将jpg格式图片转为yuv格式\n",
    "        crop_and_paste_image = self._dvpp.crop_and_paste_get_roi(yuv_image, image.width, image.height, \\\n",
    "                                self._model_width, self._model_height)  # 裁剪图片\n",
    "        return crop_and_paste_image\n",
    "\n",
    "    @utils.display_time\n",
    "    def inference(self, resized_image):\n",
    "        \"\"\"\n",
    "        model inference\n",
    "        \"\"\"\n",
    "        return self._model.execute(resized_image)\n",
    "\n",
    "    @utils.display_time\n",
    "    def post_process(self, infer_output, image_file, origin_image):\n",
    "        \"\"\"\n",
    "        post process\n",
    "        \"\"\"\n",
    "        data = ((np.squeeze(infer_output[0]) + 1) * 127.5)  # 将像素值转换到0-255之间\n",
    "        img = cv2.cvtColor(data, cv2.COLOR_RGB2BGR) \n",
    "        img = cv2.resize(img, (origin_image.width, origin_image.height))  # 缩放到原始图片大小\n",
    "        \n",
    "        # plot result\n",
    "        plt.axis('off')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        img = img[:,:,[2,1,0]]\n",
    "        plt.imshow(img/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe334c-93d9-4469-b7e3-55e588018f82",
   "metadata": {},
   "source": [
    "### 4. 构造主函数，串联整个代码逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    MODEL_PATH = \"cartoonization.om\"\n",
    "    MODEL_WIDTH = 256\n",
    "    MODEL_HEIGHT = 256\n",
    "\n",
    "    acl_resource = AclLiteResource()  # 初始化acl资源\n",
    "    acl_resource.init()\n",
    "    \n",
    "    # instantiation Cartoonization object\n",
    "    cartoonization = Cartoonization(MODEL_PATH, MODEL_WIDTH, MODEL_HEIGHT)  # 构造模型对象\n",
    "    \n",
    "    # init\n",
    "    ret = cartoonization.init()  # 初始化模型类变量\n",
    "    utils.check_ret(\"Cartoonization.init \", ret)  \n",
    "    \n",
    "\n",
    "    image_file = 'img.jpg'\n",
    "    # read image\n",
    "    image = AclLiteImage(image_file)  # 构造 AclLiteImage 对象，方便利用 dvpp 进行前处理\n",
    "    \n",
    "    print('===================')\n",
    "    print(image)\n",
    "    # preprocess\n",
    "    crop_and_paste_image = cartoonization.pre_process(image)  # 前处理\n",
    "    # inference\n",
    "    result = cartoonization.inference([crop_and_paste_image, ])  # 推理\n",
    "    # postprocess\n",
    "    cartoonization.post_process(result, image_file, image)  # 后处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd648da3-8d25-47d8-ace2-24fdd674dfa5",
   "metadata": {},
   "source": [
    "### 5. 运行\n",
    "运行完成后，会显示推理后的图片，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396dab1a-ced7-4b68-841c-810d0b3b65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c3b3f-abba-4c71-b74c-d3403b2427af",
   "metadata": {},
   "source": [
    "其中，除了acl相关资源初始化和释放的信息外，“in pre_process, use time”表示前处理耗时，“in inference, use time”表示推理耗时，“in post_process, use time”表示后处理耗时，单位都为秒。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29d51d-0e2b-4875-808a-a2deb5c91d8d",
   "metadata": {},
   "source": [
    "# 样例总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b4e3a-dd3d-4db0-bc76-55f4502ea8d9",
   "metadata": {},
   "source": [
    "我们来回顾一下以上代码，可以包括以下几个步骤：\n",
    "\n",
    "1. 初始化acl资源：在调用acl相关资源时，必须先初始化AscendCL，否则可能会导致后续系统内部资源初始化出错。  \n",
    "2. 对图片进行前处理：在此样例中，我们首先根据图片路径，构造AclLiteImage类型的数据，再利用.jpegd和.crop_and_paste_get_roi转换图片格式、裁剪图片。注意由于模型输入是yuv格式，所以我们利用了AclLiteImageProc.jpegd将图片转为yuv，使得模型正常推理。  \n",
    "3. 推理：利用AclLiteModel.execute接口对图片进行推理。  \n",
    "4. 对推理结果进行后处理：包括两个步骤，即转换像素值值域以及将图片缩放到原图大小。  \n",
    "5. 可视化图片：利用plt将结果画出。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d4380103ee16a53c08c2072b2cf7372aea12e3655e7cb36be2874465cdcb878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
