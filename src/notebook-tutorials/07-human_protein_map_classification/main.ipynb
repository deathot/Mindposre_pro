{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fef9e10-1250-45e2-a1ee-7b9b5fc5d2ea",
   "metadata": {},
   "source": [
    "# 样例介绍\n",
    "\n",
    "功能：对蛋白质图像进行自动化分类评估  \n",
    "样例输入：未标注的蛋白质荧光显微图片  \n",
    "样例输出：已经标注分类的蛋白质图谱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3900cf-1a40-4813-9072-de62e4d7d258",
   "metadata": {},
   "source": [
    "# 前期准备\n",
    "\n",
    "基础镜像的样例目录中已包含转换后的om模型以及测试图片，如果直接运行，可跳过此步骤。如果需要重新转换模型，可参考如下步骤：\n",
    "1. 获取模型和测试数据。我们可以在[这个链接](https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Atlas%20200I%20DK%20A2/DevKit/downloads/23.0.RC1/Ascend-devkit_23.0.RC1_downloads.xlsx)的表格中找到本样例的依赖文件，将模型和测试数据下载到本地，并放到本样例目录下。\n",
    "2. 模型转换。利用atc工具将原始模型转换为om模型，转换命令如下：  \n",
    "    ```shell\n",
    "    atc --model=./hpa.prototxt --weight=./hpa.caffemodel --framework=0 --output=./deploy_vel  --soc_version=Ascend310B1 --input_format=NCHW --input_fp16_nodes=data --output_type=FP32 --out_nodes=\"score:0\" \n",
    "    ```\n",
    "\n",
    "    其中各个参数具体含义如下：\n",
    "    * --model：原始模型文件。\n",
    "    * --weight：原始模型权重。\n",
    "    * --framework：原始框架类型,  0: Caffe, 1: MindSpore, 3: TensorFlow, 5: ONNX。\n",
    "    * --output：输出的模型文件路径。\n",
    "    * --soc_version：昇腾AI处理器型号，此处为\"Ascend310B1\"。\n",
    "    * --input_format：输入Tensor的内存排列方式。\n",
    "    * --input_fp16_nodes：指定输入数据类型为FP16的输入节点名称。\n",
    "    * --output_type：此处为指定某个输出节点的输出类型，需要和--out_nodes参数配合使用。\n",
    "    * --out_nodes：指定某个输出节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b67eb1-a5fb-4db8-a100-c22b0dbe6224",
   "metadata": {},
   "source": [
    "# 模型推理实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122772ee-4314-4fc7-9d79-1d3c08e34f4d",
   "metadata": {},
   "source": [
    "### 1. 导入三方库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc7d21-cf60-4491-a003-459aeebe2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import acl\n",
    "import acllite_utils as utils\n",
    "import constants as constants\n",
    "from acllite_model import AclLiteModel\n",
    "from acllite_resource import resource_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27098dd8-f6a2-4bb5-80fd-24bc8529bb3c",
   "metadata": {},
   "source": [
    "### 2. 定义acllite资源初始化与去初始化类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f003cd-0d16-47f2-97af-1dbea3e23b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AclLiteResource:\n",
    "    \"\"\"\n",
    "    AclLiteResource\n",
    "    \"\"\"\n",
    "    def __init__(self, device_id=0):\n",
    "        self.device_id = device_id\n",
    "        self.context = None\n",
    "        self.stream = None\n",
    "        self.run_mode = None\n",
    "        \n",
    "    def init(self):\n",
    "        \"\"\"\n",
    "        init resource\n",
    "        \"\"\"\n",
    "        print(\"init resource stage:\")\n",
    "        ret = acl.init()\n",
    "\n",
    "        ret = acl.rt.set_device(self.device_id)\n",
    "        utils.check_ret(\"acl.rt.set_device\", ret)\n",
    "\n",
    "        self.context, ret = acl.rt.create_context(self.device_id)\n",
    "        utils.check_ret(\"acl.rt.create_context\", ret)\n",
    "\n",
    "        self.stream, ret = acl.rt.create_stream()\n",
    "        utils.check_ret(\"acl.rt.create_stream\", ret)\n",
    "\n",
    "        self.run_mode, ret = acl.rt.get_run_mode()\n",
    "        utils.check_ret(\"acl.rt.get_run_mode\", ret)\n",
    "\n",
    "        print(\"Init resource success\")\n",
    "\n",
    "    def __del__(self):\n",
    "        print(\"acl resource release all resource\")\n",
    "        resource_list.destroy()\n",
    "        if self.stream:\n",
    "            print(\"acl resource release stream\")\n",
    "            acl.rt.destroy_stream(self.stream)\n",
    "\n",
    "        if self.context:\n",
    "            print(\"acl resource release context\")\n",
    "            acl.rt.destroy_context(self.context)\n",
    "\n",
    "        print(\"Reset acl device \", self.device_id)\n",
    "        acl.rt.reset_device(self.device_id)\n",
    "        print(\"Release acl resource success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d10a0-702a-4935-a6e5-360b5f0fa87f",
   "metadata": {},
   "source": [
    "### 3. 定义模型类，包含前处理、推理、后处理等操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178ddb8-3fd2-4c69-ac85-1d0ee9a20f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hpa(object):\n",
    "    \"\"\"\n",
    "    Class for portrait segmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, model_width, model_height):\n",
    "        self._model_path = model_path\n",
    "        self._model_width = model_width\n",
    "        self._model_height = model_height\n",
    "        self._img_width = 0\n",
    "        self._img_height = 0\n",
    "        self._model = None\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"\n",
    "        Initialize\n",
    "        \"\"\"\n",
    "        # Load model\n",
    "        self._model = AclLiteModel(self._model_path)\n",
    "\n",
    "        return constants.SUCCESS\n",
    "\n",
    "    def pre_process(self, im):\n",
    "        \"\"\"\n",
    "        image preprocess\n",
    "        \"\"\"\n",
    "        # 图片缩放\n",
    "        self._img_width = im.size[0]\n",
    "        self._img_height = im.size[1]\n",
    "        im = im.resize((224, 224))\n",
    "        img = np.array(im)\n",
    "        # rgb to bgr, HWC to CHW\n",
    "        img = img[:, :, ::-1]\n",
    "        img = img.astype(\"float16\")\n",
    "        result = img.transpose([2, 0, 1]).copy() \n",
    "        return result \n",
    "\n",
    "    def inference(self, input_data):\n",
    "        \"\"\"\n",
    "        model inference\n",
    "        \"\"\"\n",
    "        return self._model.execute(input_data)  # 推理\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        sigmod function\n",
    "        \"\"\"\n",
    "        return 1. / (1 + np.exp(-x))  # 对矩阵每个元素执行 sigmoid 操作\n",
    "\n",
    "    def visualize(self, file_name, pred):    \n",
    "        \"\"\"\n",
    "        visualize\n",
    "        \"\"\"\n",
    "\n",
    "        # 类别名称\n",
    "        id_2_label = [\n",
    "            \"Mitochondria\", \"Nucleus\", \"Endoplasmic reticulum\", \"Nuclear speckles\", \n",
    "            \"Plasma membrane\", \"Nucleoplasm\", \"Cytosol\", \"Nucleoli\",\n",
    "            \"Vesicles\", \"Golgi apparatus\"\n",
    "        ]\n",
    " \n",
    "        # 读取图片\n",
    "        setFont = ImageFont.truetype('font.ttf', 20)\n",
    "        fillColor = \"#fff\"\n",
    "        im = Image.open(file_name)\n",
    "        im = im.resize((512, 512))\n",
    "        draw = ImageDraw.Draw(im)\n",
    "        pred = pred.flatten() \n",
    "        \n",
    "        # 在图片上画出top1的类别名称与置信度\n",
    "        top1 = np.argmax(pred)\n",
    "        print(id_2_label[top1], pred[top1])\n",
    "        label =  \"%s : %.2f%%\" % (id_2_label[top1], float(pred[top1]) * 100)\n",
    "        pred[top1] = 0\n",
    "        draw.text(xy = (20, 20), text = label, font=setFont, fill=fillColor)\n",
    "        \n",
    "        # 在图片上画出top2的类别名称与置信度\n",
    "        top2 = np.argmax(pred)\n",
    "        print(top2, pred.shape)\n",
    "        label =  \"%s : %.2f%%\" % (id_2_label[top2], float(pred[top2]) * 100)\n",
    "        pred[top2] = 0\n",
    "        draw.text(xy = (20, 50), text = label, font=setFont, fill=fillColor)\n",
    "        \n",
    "        # 在图片上画出top3的类别名称与置信度\n",
    "        top3 = np.argmax(pred)\n",
    "        label =  \"%s : %.2f%%\" % (id_2_label[top3], float(pred[top3]) * 100)\n",
    "        pred[top3] = 0\n",
    "        draw.text(xy = (20, 80), text = label, font=setFont, fill=fillColor)\n",
    " \n",
    "        # show photo\n",
    "        plt.axis('off')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(im)\n",
    "\n",
    "\n",
    "    def post_process(self, result, image_name):  \n",
    "        \"\"\"\n",
    "        post_process\n",
    "        \"\"\"   \n",
    "        # 将模型输出概率压缩到0-1范围内\n",
    "        score = np.array(result[0])\n",
    "        pred = self.sigmoid(score)\n",
    "\n",
    "        # visualize\n",
    "        self.visualize(image_name, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82307d3-27ac-4d80-9b42-7d8d77aa8fc0",
   "metadata": {},
   "source": [
    "### 4. 构造主函数，串联整个代码逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070380c-78d2-458e-ac48-9fdde40ab0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    MODEL_PATH = 'deploy_vel.om'\n",
    "    MODEL_WIDTH = 224\n",
    "    MODEL_HEIGHT = 224\n",
    "    \n",
    "    # 初始化acl资源\n",
    "    acl_resource = AclLiteResource()\n",
    "    acl_resource.init()\n",
    "    \n",
    "    # 初始化模型\n",
    "    hpa = Hpa(MODEL_PATH, MODEL_WIDTH, MODEL_HEIGHT)\n",
    "    ret = hpa.init()\n",
    "    utils.check_ret(\"hpa init \", ret)\n",
    "    \n",
    "    # 读取图片\n",
    "    image_name = 'test.jpeg'\n",
    "    print('====' + image_name + '====')\n",
    "    im = Image.open(image_name)\n",
    "    if len(im.split()) != 3:\n",
    "        print('warning: \"{}\" is not a color image and will be ignored'.format(image_name))\n",
    "\n",
    "    # 前处理\n",
    "    resized_image = hpa.pre_process(im)\n",
    "\n",
    "    # 推理\n",
    "    result = hpa.inference([resized_image, ])\n",
    "\n",
    "    # 后处理\n",
    "    hpa.post_process(result, image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b94bb-7a02-4976-8946-abb280cc4edc",
   "metadata": {},
   "source": [
    "### 5. 运行\n",
    "运行完成后，会显示推理后的图片，推理结果中的置信度排名前三的类别名称，会显示在图片左上角，如下所示。推理的top1结果为Mitochondria，相应地，其置信度为64.23%，top2和top3分别为nucleoli和Nucleoplasm，相应地，其置信度为40.25%和0.41%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e38de3-421a-46ba-8bf4-8f5044192a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8061e-2c22-4252-8d26-41d76e3edb3d",
   "metadata": {},
   "source": [
    "# 样例总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940c9b0-f7a4-4872-8e45-f761c90349e8",
   "metadata": {},
   "source": [
    "我们来回顾一下以上代码，可以包括以下几个步骤：\n",
    "1. 初始化acl资源：在调用acl相关资源时，必须先初始化AscendCL，否则可能会导致后续系统内部资源初始化出错。  \n",
    "2. 对图片进行前处理：在此样例中，我们首先利用PIL读入图片，再对图片进行缩放、格式转换、维度转换等。\n",
    "3. 推理：利用AclLiteModel.execute接口对图片进行推理。    \n",
    "4. 对推理结果进行后处理：把模型输出利用sigmoid压缩到0-1范围内，转化为相应概率值，也即置信度。  \n",
    "5. 可视化图片：提取出置信度前三的分类结果，将其画在原图上。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d4380103ee16a53c08c2072b2cf7372aea12e3655e7cb36be2874465cdcb878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
